{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this project, you will build a neural network of your own design to evaluate the MNIST dataset.\n",
    "\n",
    "Some of the benchmark results on MNIST include can be found [on Yann LeCun's page](https://webcache.googleusercontent.com/search?q=cache:stAVPik6onEJ:yann.lecun.com/exdb/mnist) and include:\n",
    "\n",
    "88% [Lecun et al., 1998](https://hal.science/hal-03926082/document)\n",
    "\n",
    "95.3% [Lecun et al., 1998](https://hal.science/hal-03926082v1/document)\n",
    "\n",
    "99.65% [Ciresan et al., 2011](http://people.idsia.ch/~juergen/ijcai2011.pdf)\n",
    "\n",
    "\n",
    "MNIST is a great dataset for sanity checking your models, since the accuracy levels achieved by large convolutional neural networks and small linear models are both quite high. This makes it important to be familiar with the data.\n",
    "\n",
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the PATH to include the user installation directory. \n",
    "import os\n",
    "os.environ['PATH'] = f\"{os.environ['PATH']}:/root/.local/bin\"\n",
    "\n",
    "# Restart the Kernel before you move on to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important: Restart the Kernel before you move on to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Install requirements\n",
    "!python -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omarnagy/Downloads/migration/.conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "## This cell contains the essential imports you will need – DO NOT CHANGE THE CONTENTS! ##\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/omarnagy/Downloads/migration/Udacity_ML_Fundamentals/third project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "\n",
    "Specify your transforms as a list if you intend to .\n",
    "The transforms module is already loaded as `transforms`.\n",
    "\n",
    "MNIST is fortunately included in the torchvision module.\n",
    "Then, you can create your dataset using the `MNIST` object from `torchvision.datasets` ([the documentation is available here](https://pytorch.org/vision/stable/datasets.html#mnist)).\n",
    "Make sure to specify `download=True`! \n",
    "\n",
    "Once your dataset is created, you'll also need to define a `DataLoader` from the `torch.utils.data` module for both the train and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Check if MPS device is available\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, ), (0.5, )),\n",
    "    transforms.Lambda(lambda x: torch.flatten(x)),\n",
    "])\n",
    "\n",
    "# Create training set and define training dataloader\n",
    "trainset = torchvision.datasets.MNIST(root='/Users/omarnagy/Downloads/migration/Udacity_ML_Fundamentals/third project/MINST_Dataset', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(trainset, batch_size=2048, shuffle=True)\n",
    "\n",
    "# Create test set and define test dataloader\n",
    "testset = torchvision.datasets.MNIST(root='/Users/omarnagy/Downloads/migration/Udacity_ML_Fundamentals/third project/MINST_Dataset', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(testset, batch_size=2048, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set contains 60000 images\n",
      "Test set contains 10000 images\n",
      "Test loader contains 10000 images\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set contains {} images\".format(len(trainset)))\n",
    "print(\"Test set contains {} images\".format(len(testset)))\n",
    "print(\"Test loader contains {} images\".format(len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Justify your preprocessing\n",
    "\n",
    "In your own words, why did you choose the transforms you chose? If you didn't use any preprocessing steps, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize the pixel values to have a mean of 0.5 and a standard deviation of 0.5. This helps in stabilizing and accelerating the training process. and converting it into tensors help scaling the pixel values from [0, 255] to [0, 1] which makes the calculations easier. and flatten just flattens the input tensor to be one dimensional which is needed as being the input to the deep neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Dataset\n",
    "Using matplotlib, numpy, and torch, explore the dimensions of your data.\n",
    "\n",
    "You can view images using the `show5` function defined below – it takes a data loader as an argument.\n",
    "Remember that normalized images will look really weird to you! You may want to try changing your transforms to view images.\n",
    "Typically using no transforms other than `toTensor()` works well for viewing – but not as well for training your network.\n",
    "If `show5` doesn't work, go back and check your code for creating your data loaders and your training/test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This cell contains a function for showing 5 images from a dataloader – DO NOT CHANGE THE CONTENTS! ##\n",
    "\n",
    "def show5(img_loader):\n",
    "    dataiter = iter(img_loader)\n",
    "    batch = next(dataiter)\n",
    "    labels = batch[1][0:5]\n",
    "    images = batch[0][0:5]\n",
    "    for i in range(5):\n",
    "        print(int(labels[i].detach()))\n",
    "        image = images[i].numpy()\n",
    "        plt.imshow(image.T.squeeze().T)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore data\n",
    "show5(train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build your Neural Network\n",
    "Using the layers in `torch.nn` (which has been imported as `nn`) and the `torch.nn.functional` module (imported as `F`), construct a neural network based on the parameters of the dataset.\n",
    "Use any architecture you like. \n",
    "\n",
    "*Note*: If you did not flatten your tensors in your transforms or as part of your preprocessing and you are using only `Linear` layers, make sure to use the `Flatten` layer in your network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the class for the neural network\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(784, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        self.output = F.log_softmax\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        #x = self.output(self.fc3(x), dim=1) \n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "# Create an instance of the model\n",
    "model = Net()\n",
    "\n",
    "# upload the model to the mps device\n",
    "model.to('mps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify a loss function and an optimizer, and instantiate the model.\n",
    "\n",
    "If you use a less common loss function, please note why you chose that loss function in a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss() # multi-class classification\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "#optimizer = optim.RMSprop(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics_for_interval(i, epoch, running_loss, running_correct, running_total):\n",
    "\n",
    "    # Print statistics every 250 batches\n",
    "    if (i + 1) % 250 == 0:\n",
    "        # Calculate and print the average loss and accuracy for the last 250 batches\n",
    "        interval_loss = running_loss / 250\n",
    "        interval_accuracy = 100 * running_correct / running_total\n",
    "\n",
    "        print(f\"Epoch: {epoch + 1}, Batch: {i + 1}, Loss: {interval_loss:.4f}, Accuracy: {interval_accuracy:.2f}%\")\n",
    "\n",
    "        # Reset running totals for the next interval\n",
    "        running_correct = 0\n",
    "        running_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics_for_epoch(epoch, train_loss_history, train_correct, train_loss):\n",
    "\n",
    "    print(f\"{train_correct} of {len(train_loader.dataset)} are correct\")\n",
    "    print(f'Epoch {epoch + 1} training accuracy: {(train_correct/len(train_loader.dataset))*100:.2f}% training loss: {(train_loss/len(train_loader.dataset))*100:.5f}')\n",
    "    print()\n",
    "    # Append the loss to the history\n",
    "    train_loss_history.append(train_loss/len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(test_loader, model, loss_function, val_loss_history, epoch):\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to('mps'), labels.to('mps')\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)        \n",
    "        val_correct += (preds == labels).sum().item()\n",
    "        val_loss += loss.item()\n",
    "    \n",
    "    print(f\"{val_correct} of {len(test_loader.dataset)} are correct\")\n",
    "    print(f'Epoch {epoch + 1} validation accuracy: {(val_correct/len(test_loader.dataset))*100:.2f}% validation loss: {(val_loss/len(test_loader.dataset))*100:.5f}')\n",
    "    print()\n",
    "    # Append the validation loss to the validation loss history\n",
    "    val_loss_history.append(val_loss/len(test_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running your Neural Network\n",
    "Use whatever method you like to train your neural network, and ensure you record the average loss at each epoch. \n",
    "Don't forget to use `torch.device()` and the `.to()` method for both your model and your data if you are using GPU!\n",
    "\n",
    "If you want to print your loss **during** each epoch, you can use the `enumerate` function and print the loss after a set number of batches. 250 batches works well for most people!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4247 of 60000 are correct\n",
      "Epoch 1 training accuracy: 7.08% training loss: 0.45314\n",
      "\n",
      "745 of 10000 are correct\n",
      "Epoch 1 validation accuracy: 7.45% validation loss: 0.46065\n",
      "\n",
      "4247 of 60000 are correct\n",
      "Epoch 2 training accuracy: 7.08% training loss: 0.45316\n",
      "\n",
      "745 of 10000 are correct\n",
      "Epoch 2 validation accuracy: 7.45% validation loss: 0.46065\n",
      "\n",
      "4247 of 60000 are correct\n",
      "Epoch 3 training accuracy: 7.08% training loss: 0.45319\n",
      "\n",
      "745 of 10000 are correct\n",
      "Epoch 3 validation accuracy: 7.45% validation loss: 0.46065\n",
      "\n",
      "4247 of 60000 are correct\n",
      "Epoch 4 training accuracy: 7.08% training loss: 0.45317\n",
      "\n",
      "745 of 10000 are correct\n",
      "Epoch 4 validation accuracy: 7.45% validation loss: 0.46065\n",
      "\n",
      "4247 of 60000 are correct\n",
      "Epoch 5 training accuracy: 7.08% training loss: 0.45315\n",
      "\n",
      "745 of 10000 are correct\n",
      "Epoch 5 validation accuracy: 7.45% validation loss: 0.46065\n",
      "\n",
      "4247 of 60000 are correct\n",
      "Epoch 6 training accuracy: 7.08% training loss: 0.45313\n",
      "\n",
      "745 of 10000 are correct\n",
      "Epoch 6 validation accuracy: 7.45% validation loss: 0.46065\n",
      "\n",
      "4247 of 60000 are correct\n",
      "Epoch 7 training accuracy: 7.08% training loss: 0.45318\n",
      "\n",
      "745 of 10000 are correct\n",
      "Epoch 7 validation accuracy: 7.45% validation loss: 0.46065\n",
      "\n",
      "4247 of 60000 are correct\n",
      "Epoch 8 training accuracy: 7.08% training loss: 0.45315\n",
      "\n",
      "745 of 10000 are correct\n",
      "Epoch 8 validation accuracy: 7.45% validation loss: 0.46065\n",
      "\n",
      "4247 of 60000 are correct\n",
      "Epoch 9 training accuracy: 7.08% training loss: 0.45315\n",
      "\n",
      "745 of 10000 are correct\n",
      "Epoch 9 validation accuracy: 7.45% validation loss: 0.46065\n",
      "\n",
      "4247 of 60000 are correct\n",
      "Epoch 10 training accuracy: 7.08% training loss: 0.45314\n",
      "\n",
      "745 of 10000 are correct\n",
      "Epoch 10 validation accuracy: 7.45% validation loss: 0.46065\n",
      "\n",
      "4247 of 60000 are correct\n",
      "Epoch 11 training accuracy: 7.08% training loss: 0.45317\n",
      "\n",
      "745 of 10000 are correct\n",
      "Epoch 11 validation accuracy: 7.45% validation loss: 0.46065\n",
      "\n",
      "4247 of 60000 are correct\n",
      "Epoch 12 training accuracy: 7.08% training loss: 0.45317\n",
      "\n",
      "745 of 10000 are correct\n",
      "Epoch 12 validation accuracy: 7.45% validation loss: 0.46065\n",
      "\n",
      "4247 of 60000 are correct\n",
      "Epoch 13 training accuracy: 7.08% training loss: 0.45315\n",
      "\n",
      "745 of 10000 are correct\n",
      "Epoch 13 validation accuracy: 7.45% validation loss: 0.46065\n",
      "\n",
      "4247 of 60000 are correct\n",
      "Epoch 14 training accuracy: 7.08% training loss: 0.45317\n",
      "\n",
      "745 of 10000 are correct\n",
      "Epoch 14 validation accuracy: 7.45% validation loss: 0.46065\n",
      "\n",
      "4247 of 60000 are correct\n",
      "Epoch 15 training accuracy: 7.08% training loss: 0.45315\n",
      "\n",
      "745 of 10000 are correct\n",
      "Epoch 15 validation accuracy: 7.45% validation loss: 0.46065\n",
      "\n",
      "4247 of 60000 are correct\n",
      "Epoch 16 training accuracy: 7.08% training loss: 0.45315\n",
      "\n",
      "745 of 10000 are correct\n",
      "Epoch 16 validation accuracy: 7.45% validation loss: 0.46065\n",
      "\n",
      "4247 of 60000 are correct\n",
      "Epoch 17 training accuracy: 7.08% training loss: 0.45314\n",
      "\n",
      "745 of 10000 are correct\n",
      "Epoch 17 validation accuracy: 7.45% validation loss: 0.46065\n",
      "\n",
      "4247 of 60000 are correct\n",
      "Epoch 18 training accuracy: 7.08% training loss: 0.45314\n",
      "\n",
      "745 of 10000 are correct\n",
      "Epoch 18 validation accuracy: 7.45% validation loss: 0.46065\n",
      "\n",
      "4247 of 60000 are correct\n",
      "Epoch 19 training accuracy: 7.08% training loss: 0.45314\n",
      "\n",
      "745 of 10000 are correct\n",
      "Epoch 19 validation accuracy: 7.45% validation loss: 0.46065\n",
      "\n",
      "4247 of 60000 are correct\n",
      "Epoch 20 training accuracy: 7.08% training loss: 0.45315\n",
      "\n",
      "745 of 10000 are correct\n",
      "Epoch 20 validation accuracy: 7.45% validation loss: 0.46065\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model on the mps device and print the loss during each epoch in the training process using 250 batches \n",
    "num_epochs = 20\n",
    "\n",
    "# Establish a list for our history\n",
    "train_loss_history = list()\n",
    "val_loss_history = list()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    running_total = 0\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        # extract the inputs and labels from the data\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # upload the inputs and labels to the mps device\n",
    "        inputs, labels = inputs.to('mps'), labels.to('mps')\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        '''\n",
    "        # Compute predictions and accuracy\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        running_correct += (preds == labels).sum().item()\n",
    "        running_total += labels.size(0)\n",
    "        # Print statistics every 250 batches\n",
    "        print_statistics_for_interval(i, epoch, running_loss, running_correct, running_total)\n",
    "        '''\n",
    "        \n",
    "        # Compute the accuracy and print the accuracy and loss\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        train_correct += (preds == labels).sum().item()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    # Print statistics for the epoch    \n",
    "    print_statistics_for_epoch(epoch, train_loss_history, train_correct, train_loss)\n",
    "    \n",
    "    # Validate the model\n",
    "    validate_model(test_loader, model, loss_function, val_loss_history, epoch)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training loss (and validation loss/accuracy, if recorded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and validation loss\n",
    "plt.plot(train_loss_history, label='Training loss')\n",
    "plt.plot(val_loss_history, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing your model\n",
    "Using the previously created `DataLoader` for the test set, compute the percentage of correct predictions using the highest probability prediction. \n",
    "\n",
    "If your accuracy is over 90%, great work, but see if you can push a bit further! \n",
    "If your accuracy is under 90%, you'll need to make improvements.\n",
    "Go back and check your model architecture, loss function, and optimizer to make sure they're appropriate for an image classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# already done above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving your model\n",
    "\n",
    "Once your model is done training, try tweaking your hyperparameters and training again below to improve your accuracy on the test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59995 of 60000 are correct\n",
      "Epoch 1 training accuracy: 99.99% training loss: 0.00004\n",
      "\n",
      "9803 of 10000 are correct\n",
      "Epoch 1 validation accuracy: 98.03% validation loss: 0.06546\n",
      "\n",
      "59995 of 60000 are correct\n",
      "Epoch 2 training accuracy: 99.99% training loss: 0.00004\n",
      "\n",
      "9804 of 10000 are correct\n",
      "Epoch 2 validation accuracy: 98.04% validation loss: 0.06510\n",
      "\n",
      "59995 of 60000 are correct\n",
      "Epoch 3 training accuracy: 99.99% training loss: 0.00004\n",
      "\n",
      "9797 of 10000 are correct\n",
      "Epoch 3 validation accuracy: 97.97% validation loss: 0.06601\n",
      "\n",
      "59995 of 60000 are correct\n",
      "Epoch 4 training accuracy: 99.99% training loss: 0.00005\n",
      "\n",
      "9804 of 10000 are correct\n",
      "Epoch 4 validation accuracy: 98.04% validation loss: 0.06493\n",
      "\n",
      "59997 of 60000 are correct\n",
      "Epoch 5 training accuracy: 100.00% training loss: 0.00004\n",
      "\n",
      "9803 of 10000 are correct\n",
      "Epoch 5 validation accuracy: 98.03% validation loss: 0.06543\n",
      "\n",
      "59997 of 60000 are correct\n",
      "Epoch 6 training accuracy: 100.00% training loss: 0.00004\n",
      "\n",
      "9803 of 10000 are correct\n",
      "Epoch 6 validation accuracy: 98.03% validation loss: 0.06595\n",
      "\n",
      "59997 of 60000 are correct\n",
      "Epoch 7 training accuracy: 100.00% training loss: 0.00003\n",
      "\n",
      "9802 of 10000 are correct\n",
      "Epoch 7 validation accuracy: 98.02% validation loss: 0.06645\n",
      "\n",
      "59998 of 60000 are correct\n",
      "Epoch 8 training accuracy: 100.00% training loss: 0.00003\n",
      "\n",
      "9804 of 10000 are correct\n",
      "Epoch 8 validation accuracy: 98.04% validation loss: 0.06658\n",
      "\n",
      "59997 of 60000 are correct\n",
      "Epoch 9 training accuracy: 100.00% training loss: 0.00003\n",
      "\n",
      "9807 of 10000 are correct\n",
      "Epoch 9 validation accuracy: 98.07% validation loss: 0.06689\n",
      "\n",
      "59998 of 60000 are correct\n",
      "Epoch 10 training accuracy: 100.00% training loss: 0.00003\n",
      "\n",
      "9807 of 10000 are correct\n",
      "Epoch 10 validation accuracy: 98.07% validation loss: 0.06698\n",
      "\n",
      "59997 of 60000 are correct\n",
      "Epoch 11 training accuracy: 100.00% training loss: 0.00003\n",
      "\n",
      "9806 of 10000 are correct\n",
      "Epoch 11 validation accuracy: 98.06% validation loss: 0.06745\n",
      "\n",
      "59997 of 60000 are correct\n",
      "Epoch 12 training accuracy: 100.00% training loss: 0.00003\n",
      "\n",
      "9807 of 10000 are correct\n",
      "Epoch 12 validation accuracy: 98.07% validation loss: 0.06723\n",
      "\n",
      "59998 of 60000 are correct\n",
      "Epoch 13 training accuracy: 100.00% training loss: 0.00003\n",
      "\n",
      "9809 of 10000 are correct\n",
      "Epoch 13 validation accuracy: 98.09% validation loss: 0.06765\n",
      "\n",
      "59998 of 60000 are correct\n",
      "Epoch 14 training accuracy: 100.00% training loss: 0.00003\n",
      "\n",
      "9808 of 10000 are correct\n",
      "Epoch 14 validation accuracy: 98.08% validation loss: 0.06772\n",
      "\n",
      "59998 of 60000 are correct\n",
      "Epoch 15 training accuracy: 100.00% training loss: 0.00003\n",
      "\n",
      "9804 of 10000 are correct\n",
      "Epoch 15 validation accuracy: 98.04% validation loss: 0.06810\n",
      "\n",
      "59998 of 60000 are correct\n",
      "Epoch 16 training accuracy: 100.00% training loss: 0.00003\n",
      "\n",
      "9805 of 10000 are correct\n",
      "Epoch 16 validation accuracy: 98.05% validation loss: 0.06796\n",
      "\n",
      "59998 of 60000 are correct\n",
      "Epoch 17 training accuracy: 100.00% training loss: 0.00003\n",
      "\n",
      "9806 of 10000 are correct\n",
      "Epoch 17 validation accuracy: 98.06% validation loss: 0.06824\n",
      "\n",
      "59998 of 60000 are correct\n",
      "Epoch 18 training accuracy: 100.00% training loss: 0.00003\n",
      "\n",
      "9806 of 10000 are correct\n",
      "Epoch 18 validation accuracy: 98.06% validation loss: 0.06847\n",
      "\n",
      "59998 of 60000 are correct\n",
      "Epoch 19 training accuracy: 100.00% training loss: 0.00003\n",
      "\n",
      "9807 of 10000 are correct\n",
      "Epoch 19 validation accuracy: 98.07% validation loss: 0.06860\n",
      "\n",
      "59998 of 60000 are correct\n",
      "Epoch 20 training accuracy: 100.00% training loss: 0.00003\n",
      "\n",
      "9807 of 10000 are correct\n",
      "Epoch 20 validation accuracy: 98.07% validation loss: 0.06873\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# tbh I don't know what to do here, I'm just going to copy the code from the previous cell as I already chaged hyperparameters and the optimizer once and I got 98.09% accuracy..... so I'm just going to copy the code and run it again.\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "# Establish a list for our history\n",
    "train_loss_history = list()\n",
    "val_loss_history = list()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0\n",
    "    running_total = 0\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        # extract the inputs and labels from the data\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # upload the inputs and labels to the mps device\n",
    "        inputs, labels = inputs.to('mps'), labels.to('mps')\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        \n",
    "        # update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate loss\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        '''\n",
    "        # Compute predictions and accuracy\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        running_correct += (preds == labels).sum().item()\n",
    "        running_total += labels.size(0)\n",
    "        # Print statistics every 250 batches\n",
    "        print_statistics_for_interval(i, epoch, running_loss, running_correct, running_total)\n",
    "        '''\n",
    "        \n",
    "        # Compute the accuracy and print the accuracy and loss\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        train_correct += (preds == labels).sum().item()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    # Print statistics for the epoch    \n",
    "    print_statistics_for_epoch(epoch, train_loss_history, train_correct, train_loss)\n",
    "    \n",
    "    # Validate the model\n",
    "    validate_model(test_loader, model, loss_function, val_loss_history, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving your model\n",
    "Using `torch.save`, save your model for future loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), 'model01.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98.07%\n"
     ]
    }
   ],
   "source": [
    "# Just to make sure that the model is saved correctly, I'm going to load the model and test it on the test set.\n",
    "\n",
    "# load the model\n",
    "model = Net()\n",
    "model.load_state_dict(torch.load('model01.pth'))\n",
    "model.to('mps')\n",
    "model.eval()\n",
    "\n",
    "# test the model\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to('mps'), labels.to('mps')\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the 10000 test images: {100 * correct / total}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
